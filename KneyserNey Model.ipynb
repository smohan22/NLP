{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KneyserNey  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from math import log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kneyserNey():\n",
    "    \n",
    "    '''import pandas as pd\n",
    "    import numpy as np\n",
    "    import nltk\n",
    "    from math import log10\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #setting in fit\n",
    "        self.ngram_order = None\n",
    "        self.all_gram = None\n",
    "        self.vocab = None\n",
    "        \n",
    "    def make_ngrams(self, text, n):\n",
    "        '''\n",
    "        takes a text and n gram and creates an n-gram for it\n",
    "        '''\n",
    "        # Parse text into sentences\n",
    "        sent_text = sent_tokenize(text)\n",
    "        # Get n-grams\n",
    "        dict_ngram = {}\n",
    "        for sentence in sent_text:\n",
    "            sentence = (n-1)*\"<s> \" + sentence # create n-1 pseudo tokens\n",
    "            n_grams = nltk.ngrams(sentence.split(), n)\n",
    "            for grams in n_grams:\n",
    "                new_gram = []\n",
    "                # Change infrequent words into unknown\n",
    "                for word in grams:\n",
    "                    word = word.strip(\".\").strip(\"?\").strip(\"!\").strip(\";\").strip(\":\").strip('\"')\n",
    "                    wLower = word.lower()\n",
    "                    new_gram.append(wLower)\n",
    "                new_gram = tuple(new_gram)\n",
    "                if new_gram in dict_ngram:\n",
    "                    dict_ngram[new_gram] = dict_ngram[new_gram] + 1 \n",
    "                else:\n",
    "                    dict_ngram[new_gram] = 1\n",
    "        return dict_ngram\n",
    "\n",
    "    def fit(self, text, ngram_order):\n",
    "        '''\n",
    "        Create the fit database based on the order\n",
    "        '''\n",
    "        all_gram = {}\n",
    "        for gram in range(1, ngram_order+1):\n",
    "            all_gram[gram] = self.make_ngrams(text, gram)\n",
    "        vocab = len(all_gram[1]) -1 # -1 to take care of start phrase\n",
    "        self.ngram_order = ngram_order\n",
    "        self.all_gram = all_gram\n",
    "        self.vocab = vocab\n",
    "        return self\n",
    "    \n",
    "    def score(self, phrase, d):\n",
    "        '''\n",
    "        Performs basic checks before proceeding to calculate score of the phrase\n",
    "        '''\n",
    "        phrase = tuple(phrase.lower().split())\n",
    "        if (d <= 0 ) or (d >= 1):\n",
    "            return \"Please discounting a value between 0 and 1\"\n",
    "        elif (len(phrase) < self.ngram_order) or (len(phrase) > self.ngram_order):\n",
    "            return (\"Please give the ngram order as %d for your current phrase\" %(len(phrase)))\n",
    "        else:\n",
    "            return self.calculate_score(phrase, d)\n",
    "            \n",
    "        \n",
    "    def calculate_score(self, phrase, d):\n",
    "        '''\n",
    "        Calculate the calculate_score based on the phrase of reference\n",
    "        '''\n",
    "        ngram_len = len(phrase)\n",
    "        all_gram = self.all_gram\n",
    "        ngram_order = self.ngram_order\n",
    "        vocab = self.vocab\n",
    "        if ngram_len == 1: # base case\n",
    "            if phrase in all_gram[ngram_len]:\n",
    "                probability = all_gram[ngram_len][phrase]/vocab\n",
    "                return log10(probability) \n",
    "            else:\n",
    "                return log10(1/(vocab + 1)) # the word does not exist\n",
    "        else: #recursive case    \n",
    "            if ngram_len == ngram_order: ##counting  case\n",
    "                if phrase in all_gram[ngram_len]:\n",
    "                    num_1 = max(all_gram[ngram_len][phrase] - d, 0)\n",
    "                    num_2 = len([each for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    denom = sum([all_gram[ngram_len][each] for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    probability = num_1/denom + d*num_2/denom*self.calculate_score(phrase[1:], d)\n",
    "                    return probability\n",
    "                else:\n",
    "                    probability = self.calculate_score(phrase[1:], d) # we check for one lower gram\n",
    "                    return probability\n",
    "\n",
    "            else: #continuous counting case\n",
    "                if phrase in all_gram[ngram_len]:\n",
    "                    num_1 = max(len([each for each in all_gram[ngram_len+1] if phrase == each[1:]]) - d, 0)\n",
    "                    num_2 = len([each for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    denom = len([each for each in all_gram[ngram_len + 1 ] if phrase[:-1] == each[1:-1]])\n",
    "                    probability = num_1/denom + d*num_2/denom*self.calculate_score(phrase[1:], d)\n",
    "                    return probability\n",
    "                else:\n",
    "                    probability = self.calculate_score(phrase[1:], d) # we check for one lower gram\n",
    "                    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use Case for KneyserNey Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.3802564783641027"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter = \"\"\n",
    "with open ('Austen_Pride.txt','r') as f:\n",
    "    for line in f:\n",
    "        chapter += line\n",
    "chapter = chapter.replace('\\n', ' ').replace(\"ï»¿\", \"\").strip(\"'\").strip(\"`\")\n",
    "\n",
    "phrase='truth universally hated'\n",
    "ngram_order = 3\n",
    "d = 0.75\n",
    "prideKN = kneyserNey()\n",
    "prideKN.fit(chapter, ngram_order)\n",
    "prideKN.score(phrase, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the KneyserNey  Model on brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "#nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Brown corpus processing\n",
    "def make_sentence(text):\n",
    "    '''\n",
    "    Converts the corpus into a text with sentences\n",
    "    '''\n",
    "    text_as_sentence = \"\"\n",
    "    for word in text:\n",
    "        if word.isalpha():\n",
    "            text_as_sentence = text_as_sentence + \" \" + word\n",
    "        else:\n",
    "            text_as_sentence = text_as_sentence + word\n",
    "    return text_as_sentence        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(phrase, ngram_order, d):\n",
    "    '''\n",
    "    inputs : phrase (str) : the phrase who's score you are trying to predict\n",
    "             ngram_order ()\n",
    "    '''\n",
    "    #generate categories\n",
    "    scifi = make_sentence(brown.words(categories='science_fiction'))\n",
    "    rom = make_sentence(brown.words(categories='romance'))\n",
    "    myst = make_sentence(brown.words(categories='mystery'))\n",
    "    #make predictions\n",
    "    category = kneyserNey()\n",
    "    predict = {\"Science Fiction\" : category.fit(scifi, ngram_order).score(phrase, d), \\\n",
    "               \"Romance\" : category.fit(rom, ngram_order).score(phrase, d), \\\n",
    "               \"Mystery\" : category.fit(myst, ngram_order).score(phrase, d)}\n",
    "    #Get max value\n",
    "    return max(predict, key=predict.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use Case to choose between the genres of a particular text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Romance'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_genre('i love you', 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Science Fiction'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_genre('this is scary', 3, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mystery'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_genre('the mysterious crime', 3, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
