{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KneyserNey  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from math import log10\n",
    "\n",
    "class kneyserNey():\n",
    "    \n",
    "    '''import pandas as pd\n",
    "    import numpy as np\n",
    "    import nltk\n",
    "    from math import log10\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #setting in fit\n",
    "        self.ngram_order = None\n",
    "        self.all_gram = None\n",
    "        self.vocab = None\n",
    "    \n",
    "    \n",
    "    def make_ngrams(self, text, n):\n",
    "        '''\n",
    "        takes a text and n gram and creates an n-gram for it\n",
    "        '''\n",
    "        list_ngram = []\n",
    "        # Parse text into sentences\n",
    "        sent_text = sent_tokenize(text)\n",
    "        # Get n-grams\n",
    "        for sentence in sent_text:\n",
    "            sentence = (n-1)*\"<s> \" + sentence # create n-1 pseudo tokens\n",
    "            n_grams = nltk.ngrams(sentence.split(), n)\n",
    "            for grams in n_grams:\n",
    "                new_gram = []\n",
    "                for word in grams:\n",
    "                    word = word.strip(\".\").strip(\"?\").strip(\"!\").strip(\";\").strip(\":\").strip('\"')\n",
    "                    wLower = word.lower()\n",
    "                    new_gram.append(wLower)\n",
    "                list_ngram.append(tuple(new_gram))\n",
    "        return list_ngram\n",
    "\n",
    "    \n",
    "    def make_ngrams_counts(self, list_ngrams, n):\n",
    "        '''\n",
    "        takes a text and n gram and creates an n-gram for it\n",
    "        '''\n",
    "        dict_ngram = {}\n",
    "\n",
    "        for ngram in list_ngrams:\n",
    "            if ngram in dict_ngram:\n",
    "                dict_ngram[ngram] = dict_ngram[ngram] + 1 \n",
    "            else:\n",
    "                dict_ngram[ngram] = 1\n",
    "        return dict_ngram\n",
    "\n",
    "    \n",
    "    def fit(self, text, ngram_order):\n",
    "        '''\n",
    "        Create the fit database based on the order\n",
    "        '''\n",
    "        all_gram = {}\n",
    "        for n in range(1, ngram_order+1):\n",
    "            list_ngrams = self.make_ngrams(text, n)\n",
    "            all_gram[n] = self.make_ngrams_counts(list_ngrams, n)\n",
    "        vocab = len(all_gram[1]) -1 # -1 to take care of start phrase\n",
    "        self.ngram_order = ngram_order\n",
    "        self.all_gram = all_gram\n",
    "        self.vocab = vocab\n",
    "        return self\n",
    "    \n",
    "    def score(self, text, n, d):\n",
    "        '''\n",
    "        Performs basic checks before proceeding to calculate score of the phrase\n",
    "        '''\n",
    "        if (d <= 0 ) or (d >= 1):\n",
    "            return \"Please discounting a value between 0 and 1\"\n",
    "        else:\n",
    "            list_ngrams = self.make_ngrams(text, n) #makes ngram tuples\n",
    "            log_prob = 0\n",
    "            for phrase in list_ngrams:\n",
    "                log_prob += log10(self.calculate_score(phrase, d))\n",
    "            return log_prob\n",
    "            \n",
    "        \n",
    "    def calculate_score(self, phrase, d):\n",
    "        '''\n",
    "        Calculate the calculate_score based on the phrase of reference\n",
    "        '''\n",
    "        ngram_len = len(phrase)\n",
    "        all_gram = self.all_gram\n",
    "        ngram_order = self.ngram_order\n",
    "        vocab = self.vocab\n",
    "        if ngram_len == 1: # base case\n",
    "            if phrase in all_gram[ngram_len]:\n",
    "                probability = all_gram[ngram_len][phrase]/vocab\n",
    "                return probability\n",
    "            else:\n",
    "                return 1/(vocab + 1) # the word does not exist\n",
    "        else: #recursive case    \n",
    "            if ngram_len == ngram_order: ##counting  case\n",
    "                if phrase in all_gram[ngram_len]:\n",
    "                    num_1 = max(all_gram[ngram_len][phrase] - d, 0)\n",
    "                    num_2 = len([each for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    denom = sum([all_gram[ngram_len][each] for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    probability = num_1/denom + d*num_2/denom*self.calculate_score(phrase[1:], d)\n",
    "                    return probability\n",
    "                else:\n",
    "                    probability = self.calculate_score(phrase[1:], d) # we check for one lower gram\n",
    "                    return probability\n",
    "\n",
    "            else: #continuous counting case\n",
    "                if phrase in all_gram[ngram_len]:\n",
    "                    num_1 = max(len([each for each in all_gram[ngram_len+1] if phrase == each[1:]]) - d, 0)\n",
    "                    num_2 = len([each for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    denom = len([each for each in all_gram[ngram_len + 1 ] if phrase[:-1] == each[1:-1]])\n",
    "                    probability = num_1/denom + d*num_2/denom*self.calculate_score(phrase[1:], d)\n",
    "                    return probability\n",
    "                else:\n",
    "                    probability = self.calculate_score(phrase[1:], d) # we check for one lower gram\n",
    "                    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use Case for KneyserNey Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.3802564783641027"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter = \"\"\n",
    "with open ('Austen_Pride.txt','r') as f:\n",
    "    for line in f:\n",
    "        chapter += line\n",
    "chapter = chapter.replace('\\n', ' ').replace(\"ï»¿\", \"\").strip(\"'\").strip(\"`\")\n",
    "\n",
    "phrase='truth universally hated'\n",
    "ngram_order = 3\n",
    "d = 0.75\n",
    "prideKN = kneyserNey()\n",
    "prideKN.fit(chapter, ngram_order)\n",
    "prideKN.score(phrase, ngram_order, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the KneyserNey  Model on brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "#nltk.download('brown')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Brown corpus processing\n",
    "def make_sentence(text):\n",
    "    '''\n",
    "    Converts the corpus into a text with sentences\n",
    "    '''\n",
    "    text_as_sentence = \"\"\n",
    "    for word in text:\n",
    "        if word.isalpha():\n",
    "            text_as_sentence = text_as_sentence + \" \" + word\n",
    "        else:\n",
    "            text_as_sentence = text_as_sentence + word\n",
    "    return text_as_sentence        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_genre(phrase, ngram_order, d):\n",
    "    '''\n",
    "    inputs : phrase (str) : the phrase who's score you are trying to predict\n",
    "             ngram_order ()\n",
    "    '''\n",
    "    #generate categories\n",
    "    scifi = make_sentence(brown.words(categories='science_fiction'))\n",
    "    rom = make_sentence(brown.words(categories='romance'))\n",
    "    myst = make_sentence(brown.words(categories='mystery'))\n",
    "    #make predictions\n",
    "    category = kneyserNey()\n",
    "    predict = {\"Science Fiction\" : category.fit(scifi, ngram_order).score(phrase, ngram_order, d), \\\n",
    "               \"Romance\" : category.fit(rom, ngram_order).score(phrase, ngram_order, d), \\\n",
    "               \"Mystery\" : category.fit(myst, ngram_order).score(phrase, ngram_order, d)}\n",
    "    #Get max value\n",
    "    return max(predict, key=predict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use Case to choose between the genres of a particular text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Romance'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_genre('i love you', 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Science Fiction'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_genre('this is scary', 3, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mystery'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_genre('the mysterious crime', 3, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Science Fiction'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'It was hard enough to be forced out of my job, but it was really humiliating to be replaced by a robot. For years robots have been doing repetitive jobs like welding the same spot on products that move down an assembly line. In the last few years they have been doing more sophisticated jobs. They can assemble financial information from the internet and create a first-rate report on the market. They can take patient’s medical history as well as a trained nurse. They can even make diagnoses better than most doctors. The best surgeons now are robots. A human surgeon has to set the thing up, but the robot does the actual cutting, and the result is better than if it had been done by a human doctor.'\n",
    "\n",
    "predict_genre(text, 3, 0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
