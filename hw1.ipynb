{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add log probs, check for corner case when its a start word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter = \"\"\n",
    "with open ('Austen_Pride.txt','r') as f:\n",
    "    for line in f:\n",
    "        chapter += line\n",
    "chapter = chapter.replace('\\n', ' ').replace(\"ï»¿\", \"\").strip(\"'\").strip(\"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from math import log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter = 'truth universally hated. It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters. \"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Netherfield Park is let at last?\" Mr. Bennet replied that he had not. \"But it is,\" returned she; \"for Mrs. Long has just been here, and she told me all about it.\"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters. \"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Netherfield Park is let at last?\" Mr. Bennet replied that he had not. \"But it is,\" returned she; \"for Mrs. Long has just been here, and she told me all about it.\"'\n",
    "#chapter = \"I love going to the lake. I love going to the lake. I went to the lake. I hate going to the lake. go to the mall. come to the mall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kneyserNey():\n",
    "    '''\n",
    "    Given an n\n",
    "    '''\n",
    "    \n",
    "    '''import pandas as pd\n",
    "    import numpy as np\n",
    "    import nltk\n",
    "    from math import log10\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #setting in fit\n",
    "        self.ngram_order = None\n",
    "        self.all_gram = None\n",
    "        self.vocab = None\n",
    "        \n",
    "    def make_ngrams(self, text, n):\n",
    "        '''\n",
    "        takes a text and n gram and creates an n-gram for it\n",
    "        '''\n",
    "        # Parse text into sentences\n",
    "        sent_text = sent_tokenize(text)\n",
    "        # Get n-grams\n",
    "        dict_ngram = {}\n",
    "        for sentence in sent_text:\n",
    "            sentence = (n-1)*\"<s> \" + sentence # create n-1 pseudo tokens\n",
    "            n_grams = nltk.ngrams(sentence.split(), n)\n",
    "            for grams in n_grams:\n",
    "                new_gram = []\n",
    "                # Change infrequent words into unknown\n",
    "                for word in grams:\n",
    "                    word = word.strip(\".\")\n",
    "                    wLower = word.lower()\n",
    "                    new_gram.append(wLower)\n",
    "                new_gram = tuple(new_gram)\n",
    "                if new_gram in dict_ngram:\n",
    "                    dict_ngram[new_gram] = dict_ngram[new_gram] + 1 \n",
    "                else:\n",
    "                    dict_ngram[new_gram] = 1\n",
    "        return dict_ngram\n",
    "\n",
    "    def fit(self, text, ngram_order):\n",
    "        all_gram = {}\n",
    "        for gram in range(1, ngram_order+1):\n",
    "            all_gram[gram] = self.make_ngrams(text, gram)\n",
    "        vocab = len(all_gram[1]) -1 # -1 to take care of start phrase\n",
    "        self.ngram_order = ngram_order\n",
    "        self.all_gram = all_gram\n",
    "        self.vocab = vocab\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def score(self, phrase, d):\n",
    "        ngram_len = len(phrase)\n",
    "        all_gram = self.all_gram\n",
    "        ngram_order = self.ngram_order\n",
    "        vocab = self.vocab\n",
    "        if ngram_len == 1: # base case\n",
    "            if phrase in all_gram[ngram_len]:\n",
    "                probability = all_gram[ngram_len][phrase]/vocab\n",
    "                return probability\n",
    "            else:\n",
    "                return 1/(vocab + 1) # the word does not exist\n",
    "        else: #recursive case    \n",
    "            if ngram_len == ngram_order: ##counting  case\n",
    "                if phrase in all_gram[ngram_len]:\n",
    "                    num_1 = max(all_gram[ngram_len][phrase] - d, 0)\n",
    "                    num_2 = len([each for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    denom = sum([all_gram[ngram_len][each] for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    probability = num_1/denom + d*num_2/denom*self.score(phrase[1:], d)\n",
    "                    return probability\n",
    "                else:\n",
    "                    print(ngram_len, \"counting + notfound\")\n",
    "                    probability = self.score(phrase[1:], d) # we check for one lower gram\n",
    "                    return probability\n",
    "\n",
    "            else: #continuous counting case\n",
    "                if phrase in all_gram[ngram_len]:\n",
    "                    num_1 = max(len([each for each in all_gram[ngram_len+1] if phrase == each[1:]]) - d, 0)\n",
    "                    num_2 = len([each for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    denom = len([each for each in all_gram[ngram_len + 1 ] if phrase[:-1] == each[1:-1]])\n",
    "                    probability = num_1/denom + d*num_2/denom*self.score(phrase[1:], d)\n",
    "                    return probability\n",
    "                else:\n",
    "                    print(ngram_len,\"continn counting +not found\")\n",
    "                    probability = self.score(phrase[1:], d) # we check for one lower gram\n",
    "                    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase=('truth', 'universally', 'hated,')\n",
    "ngram_order = 3\n",
    "d = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prideKN = kneyserNey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.kneyserNey at 0x25de9717da0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prideKN.fit(chapter, ngram_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 counting + notfound\n",
      "2 continn counting +not found\n",
      "base + notfound\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.9542425094393248"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prideKN.score(phrase, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"i am sam x. sam am i x. i am sam x. i do not like green eggs and sam x.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3d2a4cd1e1eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgram\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mprideKN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_gram\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "gram =prideKN.fit(text, 2).all_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-810f56b025c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gram' is not defined"
     ]
    }
   ],
   "source": [
    "len(gram[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
