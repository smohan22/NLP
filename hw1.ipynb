{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter = \"\"\n",
    "with open ('Austen_Pride.txt','r') as f:\n",
    "    for line in f:\n",
    "        chapter += line\n",
    "chapter = chapter.replace('\\n', ' ').replace(\"ï»¿\", \"\").strip(\"'\").strip(\"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter = 'truth universally hated. It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters. \"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Netherfield Park is let at last?\" Mr. Bennet replied that he had not. \"But it is,\" returned she; \"for Mrs. Long has just been here, and she told me all about it.\"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters. \"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Netherfield Park is let at last?\" Mr. Bennet replied that he had not. \"But it is,\" returned she; \"for Mrs. Long has just been here, and she told me all about it.\"'\n",
    "#chapter = \"I love going to the lake. I love going to the lake. I went to the lake. I hate going to the lake. go to the mall. come to the mall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kneyserNey():\n",
    "    '''\n",
    "    Given a text, n (in ngram), threshold to consider words as '<UNK>', fit an ngram model\n",
    "    Given a new ngram, calculate its Kneyser-Ney probability\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.text = text\n",
    "        self.phrase = phrase\n",
    "        self.d = d\n",
    "        self.ngram_order = ngram_order\n",
    "        \n",
    "    def make_ngrams(self, text, n):\n",
    "        # Parse text into sentences\n",
    "        sent_text = nltk.sent_tokenize(text)\n",
    "        # Get n-grams\n",
    "        dict_ngram = {}\n",
    "        for sentence in sent_text:\n",
    "            sentence = \"<s> \" + sentence\n",
    "            n_grams = nltk.ngrams(sentence.split(), n)\n",
    "            for grams in n_grams:\n",
    "                new_gram = []\n",
    "                # Change infrequent words into unknown\n",
    "                for word in grams:\n",
    "                    word = word.strip(\".\")\n",
    "                    wLower = word.lower()\n",
    "                    new_gram.append(wLower)\n",
    "                new_gram = tuple(new_gram)\n",
    "                if new_gram in dict_ngram:\n",
    "                    dict_ngram[new_gram] = dict_ngram[new_gram] + 1 \n",
    "                else:\n",
    "                    dict_ngram[new_gram] = 1\n",
    "        return dict_ngram\n",
    "\n",
    "    def fit(self, text,ngram_order, d):\n",
    "        all_gram = {}\n",
    "        for gram in range(1, ngram_order+1):\n",
    "            all_gram[gram] = self.make_ngrams(text, gram)\n",
    "        vocab = len(all_gram[1]) -1 # -1 to take care of start phrase\n",
    "        return all_gram, vocab\n",
    "    \n",
    "    \n",
    "    def score(self, phrase, ngram_len):\n",
    "        if ngram_len == 1: # base case\n",
    "            if phrase in all_gram[ngram_len]:\n",
    "                print(\"base + found\")\n",
    "                probability = all_gram[ngram_len][phrase]/vocab\n",
    "                return probability\n",
    "            else:\n",
    "                print(\"base + notfound\")\n",
    "                return 1/(vocab + 1) # the word does not exist\n",
    "        else: #recursive case    \n",
    "            if ngram_len == ngram_order: ##counting  case\n",
    "                if phrase in all_gram[ngram_len]:\n",
    "                    print(ngram_len, \"counting + found\")\n",
    "                    num_1 = max(all_gram[ngram_len][phrase] - d, 0)\n",
    "                    num_2 = len([each for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    denom = sum([all_gram[ngram_len][each] for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    probability = num_1/denom + d*num_2/denom*(self.score(phrase[1:], ngram_len - 1))\n",
    "                    return probability\n",
    "                else:\n",
    "                    print(ngram_len, \"counting + notfound\")\n",
    "                    probability = self.score(phrase[1:], ngram_len - 1) # we check for one lower gram\n",
    "                    return probability\n",
    "\n",
    "            else: #continuous counting case\n",
    "                if phrase in all_gram[ngram_len]:\n",
    "                    print(ngram_len, \"continn counting + found\")\n",
    "                    num_1 = max(len([each for each in all_gram[ngram_len+1] if phrase == each[1:]]) - d, 0)\n",
    "                    num_2 = len([each for each in all_gram[ngram_len] if phrase[:-1] == each[:-1]])\n",
    "                    denom = len([each for each in all_gram[ngram_len + 1 ] if phrase[:-1] == each[1:-1]])\n",
    "                    probability = num_1/denom + d*num_2/denom*(self.score(phrase[1:], ngram_len - 1))\n",
    "                    return probability\n",
    "                else:\n",
    "                    print(ngram_len,\"continn counting +not found\")\n",
    "                    probability = self.score(phrase[1:], ngram_len - 1) # we check for one lower gram\n",
    "                    return probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 counting + notfound\n",
      "2 continn counting +not found\n",
      "base + notfound\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011111111111111112"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase=('truth', 'universally', 'hated,')\n",
    "ngram_order = 3\n",
    "d = 0.75\n",
    "calc_kneser_ney(phrase, ngram_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-395f37543bc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprideKN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkneyserNey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 5 were given"
     ]
    }
   ],
   "source": [
    "prideKN = kneyserNey(chapter, phrase, d, ngram_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-193-0e079198f2f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprideKN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "prideKN.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {('truth', 'universally', 'acknowledged,'): 1}\n",
    "c =  ('truth', 'universally', 'acknowledged,')\n",
    "c[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08333333333333333"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/ (vocab+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
